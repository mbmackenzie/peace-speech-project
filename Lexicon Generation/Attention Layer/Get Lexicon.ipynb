{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15051,
     "status": "ok",
     "timestamp": 1609837112469,
     "user": {
      "displayName": "Matt Mackenzie",
      "photoUrl": "",
      "userId": "00984319682251569642"
     },
     "user_tz": 300
    },
    "id": "McsQDmd_GrpY",
    "outputId": "c049aa23-30fb-4e5f-a1bd-06a48af06422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3326,
     "status": "ok",
     "timestamp": 1609837121286,
     "user": {
      "displayName": "Matt Mackenzie",
      "photoUrl": "",
      "userId": "00984319682251569642"
     },
     "user_tz": 300
    },
    "id": "y-NgSzIS4pUM",
    "outputId": "f276ecfb-17ad-4658-b1b3-dfc636165fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import sys\r\n",
    "from imp import reload\r\n",
    "from collections import defaultdict\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "if sys.version[0] == '2':\r\n",
    "    reload(sys)\r\n",
    "    sys.setdefaultencoding(\"utf-8\")\r\n",
    "\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import nltk\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('wordnet')\r\n",
    "\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow.keras as keras\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\r\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\r\n",
    "from tensorflow.keras.models import Model, Sequential\r\n",
    "from tensorflow.keras.layers import Convolution1D\r\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 25012,
     "status": "ok",
     "timestamp": 1609837151236,
     "user": {
      "displayName": "Matt Mackenzie",
      "photoUrl": "",
      "userId": "00984319682251569642"
     },
     "user_tz": 300
    },
    "id": "KhInAo_fHIFh",
    "outputId": "09dec052-34c2-4578-b218-70abed1df912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417941, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>article_id</th>\n",
       "      <th>country</th>\n",
       "      <th>publisher</th>\n",
       "      <th>year</th>\n",
       "      <th>article_text</th>\n",
       "      <th>society</th>\n",
       "      <th>is_peaceful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>71409778</td>\n",
       "      <td>AU</td>\n",
       "      <td>perthnow.com.au</td>\n",
       "      <td>2019</td>\n",
       "      <td>Labor continue pursuit Angus Taylor Federal La...</td>\n",
       "      <td>peaceful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71101824</td>\n",
       "      <td>AU</td>\n",
       "      <td>perthnow.com.au</td>\n",
       "      <td>2019</td>\n",
       "      <td>For many year South Australia unenviable reput...</td>\n",
       "      <td>peaceful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71512141</td>\n",
       "      <td>AU</td>\n",
       "      <td>perthnow.com.au</td>\n",
       "      <td>2019</td>\n",
       "      <td>Jamie Maclaren open join Melbourne City tough ...</td>\n",
       "      <td>peaceful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71147035</td>\n",
       "      <td>AU</td>\n",
       "      <td>perthnow.com.au</td>\n",
       "      <td>2019</td>\n",
       "      <td>Perth man hang arm drug gang Rio favela Topics...</td>\n",
       "      <td>peaceful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>71206307</td>\n",
       "      <td>AU</td>\n",
       "      <td>perthnow.com.au</td>\n",
       "      <td>2019</td>\n",
       "      <td>MP allegedly told fake donor lie ICAC Dominica...</td>\n",
       "      <td>peaceful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656179</th>\n",
       "      <td>656870</td>\n",
       "      <td>14014747</td>\n",
       "      <td>TZ</td>\n",
       "      <td>Daily News | The National Newspaper (press rel...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Principal Resident Magistrate Dr Yohana Yongol...</td>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656180</th>\n",
       "      <td>656871</td>\n",
       "      <td>14806484</td>\n",
       "      <td>TZ</td>\n",
       "      <td>Daily News | The National Newspaper (press rel...</td>\n",
       "      <td>2016</td>\n",
       "      <td>FULLY FLEDGED Yoga Instructors Susan Tabula fa...</td>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656181</th>\n",
       "      <td>656872</td>\n",
       "      <td>9047182</td>\n",
       "      <td>TZ</td>\n",
       "      <td>Daily News | The National Newspaper (press rel...</td>\n",
       "      <td>2016</td>\n",
       "      <td>THE government divulge content report Judicial...</td>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656182</th>\n",
       "      <td>656873</td>\n",
       "      <td>13915423</td>\n",
       "      <td>TZ</td>\n",
       "      <td>Daily News | The National Newspaper (press rel...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Ambassador Egypt Tanzania Mr Yasser Elshawaf t...</td>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656183</th>\n",
       "      <td>656874</td>\n",
       "      <td>13994764</td>\n",
       "      <td>TZ</td>\n",
       "      <td>Daily News | The National Newspaper (press rel...</td>\n",
       "      <td>2016</td>\n",
       "      <td>The doctor bitter spiritual healer end delay f...</td>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417941 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  article_id  ...      society is_peaceful\n",
       "0            0    71409778  ...     peaceful        True\n",
       "1            1    71101824  ...     peaceful        True\n",
       "2            2    71512141  ...     peaceful        True\n",
       "3            3    71147035  ...     peaceful        True\n",
       "4            4    71206307  ...     peaceful        True\n",
       "...        ...         ...  ...          ...         ...\n",
       "656179  656870    14014747  ...  nonpeaceful       False\n",
       "656180  656871    14806484  ...  nonpeaceful       False\n",
       "656181  656872     9047182  ...  nonpeaceful       False\n",
       "656182  656873    13915423  ...  nonpeaceful       False\n",
       "656183  656874    13994764  ...  nonpeaceful       False\n",
       "\n",
       "[417941 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\r\n",
    "\r\n",
    "def get_society_label(country: str, peaceful: List[str], nonpeaceful: List[str]) -> str:\r\n",
    "  if country in peaceful:\r\n",
    "    return \"peaceful\"\r\n",
    "  elif country in nonpeaceful:\r\n",
    "    return \"nonpeaceful\"\r\n",
    "  else:\r\n",
    "    return \"other\"\r\n",
    "\r\n",
    "def country_is_peaceful(society):\r\n",
    "  return society.lower() == \"peaceful\"\r\n",
    "\r\n",
    "BASE_DIR = \"/content/drive/MyDrive/peace-speech-project/\"\r\n",
    "\r\n",
    "peaceful_countries = ['GB', 'AU', 'CA', 'SG', 'NZ', 'IE']\r\n",
    "non_peaceful_countries = ['PK', 'BD', 'NG', 'KE', 'ZA', 'TZ']\r\n",
    "\r\n",
    "data_file_path = os.path.join(BASE_DIR, \"data\", \"domestic_articles__ngram__stopwords__lemmatized.csv\")\r\n",
    "articles = pd.read_csv(data_file_path, index_col=[0])\r\n",
    "articles = articles.dropna().reset_index()\r\n",
    "\r\n",
    "articles[\"society\"] = articles.country.apply(\r\n",
    "    get_society_label, \r\n",
    "    peaceful=peaceful_countries, \r\n",
    "    nonpeaceful=non_peaceful_countries\r\n",
    ")\r\n",
    "\r\n",
    "articles[\"is_peaceful\"] = articles.society.apply(country_is_peaceful)\r\n",
    "articles = articles[articles.society != \"other\"].copy()\r\n",
    "\r\n",
    "print(articles.shape)\r\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112390,
     "status": "ok",
     "timestamp": 1609837240344,
     "user": {
      "displayName": "Matt Mackenzie",
      "photoUrl": "",
      "userId": "00984319682251569642"
     },
     "user_tz": 300
    },
    "id": "q0SUy49eIEtp",
    "outputId": "cf1a8f60-190e-448d-cabd-a2d6eed4751f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 131 ms, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "\r\n",
    "MAX_FEATURES = 6000\r\n",
    "EMBED_SIZE = 128\r\n",
    "RNN_CELL_SIZE = 32\r\n",
    "MAX_LEN = 371\r\n",
    "\r\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\r\n",
    "tokenizer.fit_on_texts(articles['article_text'])\r\n",
    "reverse_word_index = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 116770,
     "status": "ok",
     "timestamp": 1609837245751,
     "user": {
      "displayName": "Matt Mackenzie",
      "photoUrl": "",
      "userId": "00984319682251569642"
     },
     "user_tz": 300
    },
    "id": "wyRS_N9dGoTC"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\r\n",
    "    def __init__(self, units):\r\n",
    "        super(Attention, self).__init__()\r\n",
    "        self.W1 = tf.keras.layers.Dense(units)\r\n",
    "        self.W2 = tf.keras.layers.Dense(units)\r\n",
    "        self.V = tf.keras.layers.Dense(1)\r\n",
    " \r\n",
    "    def call(self, features, hidden):\r\n",
    "        # hidden shape == (batch_size, hidden size)\r\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\r\n",
    "        # we are doing this to perform addition to calculate the score\r\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\r\n",
    "\r\n",
    "        # score shape == (batch_size, max_length, 1)\r\n",
    "        # we get 1 at the last axis because we are applying score to self.V\r\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\r\n",
    "        score = tf.nn.tanh(\r\n",
    "            self.W1(features) + self.W2(hidden_with_time_axis))\r\n",
    "        \r\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\r\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\r\n",
    "\r\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\r\n",
    "        context_vector = attention_weights * features\r\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\r\n",
    " \r\n",
    "        return context_vector, attention_weights\r\n",
    "\r\n",
    "METRICS = [\r\n",
    "      keras.metrics.TruePositives(name='tp'),\r\n",
    "      keras.metrics.FalsePositives(name='fp'),\r\n",
    "      keras.metrics.TrueNegatives(name='tn'),\r\n",
    "      keras.metrics.FalseNegatives(name='fn'), \r\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\r\n",
    "      keras.metrics.Precision(name='precision'),\r\n",
    "      keras.metrics.Recall(name='recall'),\r\n",
    "      keras.metrics.AUC(name='auc'),\r\n",
    "]\r\n",
    "\r\n",
    "def build_model(return_attention=False):\r\n",
    "  sequence_input = Input(shape=(MAX_LEN,), dtype=\"int32\")\r\n",
    "  embedded_sequences = Embedding(MAX_FEATURES, EMBED_SIZE)(sequence_input)\r\n",
    "\r\n",
    "  lstm = Bidirectional(LSTM(RNN_CELL_SIZE, return_sequences = True), name=\"bi_lstm_0\")(embedded_sequences)\r\n",
    "\r\n",
    "  # Getting our LSTM outputs\r\n",
    "  (lstm, forward_h, forward_c, backward_h, backward_c) = Bidirectional(\r\n",
    "      LSTM(\r\n",
    "          RNN_CELL_SIZE, \r\n",
    "          return_sequences=True, \r\n",
    "          return_state=True\r\n",
    "      ), name=\"bi_lstm_1\"\r\n",
    "  )(lstm)\r\n",
    "\r\n",
    "\r\n",
    "  state_h = Concatenate()([forward_h, backward_h])\r\n",
    "  state_c = Concatenate()([forward_c, backward_c])\r\n",
    "\r\n",
    "  context_vector, attention_weights = Attention(10)(lstm, state_h)\r\n",
    "  attention_model = keras.Model(inputs=sequence_input, outputs=attention_weights)  ## Attention Model\r\n",
    "\r\n",
    "  dense1 = Dense(20, activation=\"relu\")(context_vector)\r\n",
    "  dropout = Dropout(0.05)(dense1)\r\n",
    "  output = Dense(1, activation=\"sigmoid\")(dropout)\r\n",
    "\r\n",
    "  model = keras.Model(inputs=sequence_input, outputs=output)\r\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\r\n",
    "\r\n",
    "  if return_attention:\r\n",
    "    return model, attention_model\r\n",
    "  else:\r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 118732,
     "status": "ok",
     "timestamp": 1609837248880,
     "user": {
      "displayName": "Matt Mackenzie",
      "photoUrl": "",
      "userId": "00984319682251569642"
     },
     "user_tz": 300
    },
    "id": "zDsAGnxBHBIx"
   },
   "outputs": [],
   "source": [
    "model, attention_model = build_model(return_attention=True)\r\n",
    "model.load_weights(os.path.join(BASE_DIR, \"Attention Layer Lexicon\", \"attention_base_model.h5\"))\r\n",
    "attention_model.load_weights(os.path.join(BASE_DIR, \"Attention Layer Lexicon\", \"attention_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 118388,
     "status": "ok",
     "timestamp": 1609837248881,
     "user": {
      "displayName": "Matt Mackenzie",
      "photoUrl": "",
      "userId": "00984319682251569642"
     },
     "user_tz": 300
    },
    "id": "CbBRXwxPH3zf"
   },
   "outputs": [],
   "source": [
    "def get_attention_weights(keras_tokenizer, attention_model, article_text, reverse_word_index, maxlen=MAX_LEN):\r\n",
    "  article_sequence = pad_sequences(keras_tokenizer.texts_to_sequences([article_text]), maxlen=maxlen)\r\n",
    "  attention_weights_array = attention_model.predict(article_sequence).reshape(1, maxlen)\r\n",
    "  attention_weights_dict = defaultdict(list)\r\n",
    "\r\n",
    "  for len_ind in range(maxlen):\r\n",
    "    try:\r\n",
    "      attention_weights_dict[reverse_word_index[article_sequence[0][len_ind]]].append(attention_weights_array[0][len_ind])\r\n",
    "    except Exception:\r\n",
    "      continue\r\n",
    "  \r\n",
    "  \r\n",
    "  weights_df = pd.DataFrame(attention_weights_dict.items(), columns=[\"term\", \"weights\"])\r\n",
    "  weights_df[\"n_weights\"] = weights_df.weights.apply(lambda x: len(x))\r\n",
    "  weights_df[\"max_weight\"] = weights_df.weights.apply(lambda x: np.max(x))\r\n",
    "  weights_df[\"mean_weight\"] = weights_df.weights.apply(lambda x: np.mean(x))\r\n",
    "  weights_df[\"var_weight\"] = weights_df.weights.apply(lambda x: np.var(x))\r\n",
    "  weights_df[\"median_weight\"] = weights_df.weights.apply(lambda x: np.median(x))\r\n",
    "\r\n",
    "  return weights_df\r\n",
    "\r\n",
    "def apply_get_attention_weights(tbl, n, field):\r\n",
    "  row = tbl.iloc[0, :]\r\n",
    "  weights = get_attention_weights(\r\n",
    "      keras_tokenizer=tokenizer, \r\n",
    "      attention_model=attention_model,\r\n",
    "      article_text=row.article_text, \r\n",
    "      reverse_word_index=reverse_word_index\r\n",
    "  )\r\n",
    "\r\n",
    "  return weights.sort_values(field, ascending=False).head(n)[[\"term\", field]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0u9mK6VI3qx"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d098cf81e58e4febad9d2945e87ca7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=402150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\r\n",
    "top_terms_by_article = articles.groupby([\"article_id\", \"society\", \"country\", \"year\"]).progress_apply(\r\n",
    "    apply_get_attention_weights, n=5, field=\"mean_weight\"\r\n",
    ").reset_index().drop(\"level_4\", axis=1)\r\n",
    "\r\n",
    "top_terms_by_article.to_csv(os.path.join(BASE_DIR, \"Attention Layer Lexicon\", \"top_terms_by_mean_weight__articles.csv\"))\r\n",
    "top_terms_by_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ltZ4vNbcJKkI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>society</th>\n",
       "      <th>term</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>kenya</td>\n",
       "      <td>4559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>'s</td>\n",
       "      <td>3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>nigerian</td>\n",
       "      <td>2681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nonpeaceful</td>\n",
       "      <td>abuja</td>\n",
       "      <td>2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>future</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>issue</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>statement</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>big</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>order</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         society       term     n\n",
       "0    nonpeaceful    nigeria  6857\n",
       "1    nonpeaceful      kenya  4559\n",
       "2    nonpeaceful         's  3276\n",
       "3    nonpeaceful   nigerian  2681\n",
       "4    nonpeaceful      abuja  2561\n",
       "..           ...        ...   ...\n",
       "395     peaceful     future  1315\n",
       "396     peaceful      issue  1314\n",
       "397     peaceful  statement  1309\n",
       "398     peaceful        big  1301\n",
       "399     peaceful      order  1301\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms = top_terms_by_article.groupby([\"society\", \"term\"]).size().rename(\"n\").reset_index()\r\n",
    "top_terms = top_terms.groupby(\"society\").apply(lambda x: x.nlargest(200, [\"n\"])).reset_index(drop=True)\r\n",
    "top_terms.to_csv(os.path.join(BASE_DIR, \"Attention Layer Lexicon\", \"top_terms_by_mean_weight__agg.csv\"))\r\n",
    "top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtOukg7jO3C1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPUifaILrgsDc5Pm/wXH5ep",
   "collapsed_sections": [],
   "name": "Attention Layer Lexicon - Get Lexicon",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d098cf81e58e4febad9d2945e87ca7e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ccb5d79ba0514f399525267fc7b89650",
       "IPY_MODEL_3853f66b7fc94fa99a8ecb2d61736323"
      ],
      "layout": "IPY_MODEL_dfba95c123ae45ce8d3eefe1195f106d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
