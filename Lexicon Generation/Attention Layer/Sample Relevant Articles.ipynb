{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattb\\Miniconda3\\envs\\peace\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "sampled_articles = pd.read_csv(\"../data/sampled_articles_details.csv\")\n",
    "\n",
    "lexicon = pd.read_csv(\"Sensitivity/norm_lexicon__5.csv\")\n",
    "top_terms_articles = pd.read_csv(\"top_terms_by_mean_weight__articles.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_articles = lexicon.merge(top_terms_articles, on=\"term\", how=\"left\")\n",
    "\n",
    "possible_articles = lexicon_articles.groupby(\"article_id\") \\\n",
    "    .size() \\\n",
    "    .rename(\"n\") \\\n",
    "    .reset_index() \\\n",
    "    .query(\"n >= 4\")\n",
    "\n",
    "filtered_terms = lexicon_articles[lexicon_articles.article_id.isin(possible_articles.article_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1844601, 30977823, 1884282, 1793428, 40533898, 40881127, 30865248, 1866797, 14060426, 1815672, 1680309, 24167359, 3069080, 60626294, 40374416, 41990744, 42122954, 1172040, 2803082, 830141]\n"
     ]
    }
   ],
   "source": [
    "anec_articles_ids = filtered_terms.groupby([\"society\", \"article_id\"]) \\\n",
    "    .size() \\\n",
    "    .rename(\"n\") \\\n",
    "    .reset_index() \\\n",
    "    .groupby(\"society\") \\\n",
    "    .sample(10, random_state=116) \\\n",
    "    .article_id \\\n",
    "    .to_list()\n",
    "\n",
    "print(anec_articles_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46327</th>\n",
       "      <td>24167359</td>\n",
       "      <td>Motor race Gasly come back earth bump SHANGHAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76199</th>\n",
       "      <td>30865248</td>\n",
       "      <td>U 16 clinch one day series well The third fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76263</th>\n",
       "      <td>30977823</td>\n",
       "      <td>Fifth grader rap Kurigram Accused try cover Ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80125</th>\n",
       "      <td>60626294</td>\n",
       "      <td>As Ottawa free fall Belleville soar Senators p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113936</th>\n",
       "      <td>830141</td>\n",
       "      <td>Terence Corcoran Canada 's Big Fat Chobani Gre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id                                       article_text\n",
       "46327     24167359  Motor race Gasly come back earth bump SHANGHAI...\n",
       "76199     30865248  U 16 clinch one day series well The third fina...\n",
       "76263     30977823  Fifth grader rap Kurigram Accused try cover Ku...\n",
       "80125     60626294  As Ottawa free fall Belleville soar Senators p...\n",
       "113936      830141  Terence Corcoran Canada 's Big Fat Chobani Gre..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_data = pd.read_csv(\"../data/domestic_articles__ngram__stopwords__lemmatized.csv\", usecols=[1, 5])\n",
    "anec_articles_rnn_text = rnn_data[rnn_data.article_id.isin(anec_articles_ids)].copy()\n",
    "\n",
    "del rnn_data\n",
    "anec_articles_rnn_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>top_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>830141</td>\n",
       "      <td>[please, produce, send, already, along]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1172040</td>\n",
       "      <td>[united, kingdom, follow, require, recently]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1680309</td>\n",
       "      <td>[except, certain, require, site, around]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1793428</td>\n",
       "      <td>[usually, grace, abroad, meant, also]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1815672</td>\n",
       "      <td>[embark, please, lose, according, leave]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                     top_terms\n",
       "0      830141       [please, produce, send, already, along]\n",
       "1     1172040  [united, kingdom, follow, require, recently]\n",
       "2     1680309      [except, certain, require, site, around]\n",
       "3     1793428         [usually, grace, abroad, meant, also]\n",
       "4     1815672      [embark, please, lose, according, leave]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anec_articles_top_terms = top_terms_articles[\n",
    "    top_terms_articles.article_id.isin(anec_articles_ids)\n",
    "] \\\n",
    "    .groupby(\"article_id\") \\\n",
    "    .apply(lambda x: x.term.values) \\\n",
    "    .rename(\"top_terms\") \\\n",
    "    .reset_index()\n",
    "\n",
    "anec_articles_top_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sample_path = os.path.join(\"D:\", \"Peace Speech Project Drive\", \"clean_sample\")\n",
    "raw_sample_path = os.path.join(\"D:\", \"Peace Speech Project Drive\", \"sample_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <td>sbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>24167359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <td>24167359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_publisher</th>\n",
       "      <td>SBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_text</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>AU\\sbs\\2018\\24167359_AU_15-04-18.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_terms</th>\n",
       "      <td>[subscribe, australia, follow, listen, around]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_text</th>\n",
       "      <td>Motor race Gasly come back earth bump SHANGHAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_title</th>\n",
       "      <td>Motor Racing - Gasly Comes Back Down To Earth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_og_text</th>\n",
       "      <td>&lt;h&gt; Motor racing - Gasly comes back down to ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>society</th>\n",
       "      <td>peaceful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0\n",
       "country                                                           AU\n",
       "publisher                                                        sbs\n",
       "year                                                            2018\n",
       "month                                                              4\n",
       "id                                                          24167359\n",
       "article_id                                                  24167359\n",
       "article_publisher                                                SBS\n",
       "has_text                                                        True\n",
       "path                            AU\\sbs\\2018\\24167359_AU_15-04-18.txt\n",
       "top_terms             [subscribe, australia, follow, listen, around]\n",
       "article_text       Motor race Gasly come back earth bump SHANGHAI...\n",
       "article_title      Motor Racing - Gasly Comes Back Down To Earth ...\n",
       "article_og_text    <h> Motor racing - Gasly comes back down to ea...\n",
       "society                                                     peaceful"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anec_article = sampled_articles[\n",
    "    sampled_articles.article_id.isin(anec_articles_ids)\n",
    "].copy()\n",
    "\n",
    "anec_article = anec_article.merge(\n",
    "    anec_articles_top_terms, on=\"article_id\"\n",
    ")\n",
    "\n",
    "anec_article = anec_article.merge(\n",
    "    anec_articles_rnn_text, on=\"article_id\"\n",
    ")\n",
    "\n",
    "def get_title(p):\n",
    "    with open(os.path.join(clean_sample_path, p)) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "        \n",
    "    return lines[1].strip().title()\n",
    "\n",
    "def get_og_text(p):\n",
    "    with open(os.path.join(raw_sample_path, p)) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "        \n",
    "    return lines[-1].strip()\n",
    "\n",
    "anec_article[\"article_title\"] = anec_article.path.apply(get_title)\n",
    "anec_article[\"article_og_text\"] = anec_article.path.apply(get_og_text)\n",
    "\n",
    "peaceful_countries = ['GB', 'AU', 'CA', 'SG', 'NZ', 'IE']\n",
    "non_peaceful_countries = ['PK', 'BD', 'NG', 'KE', 'ZA', 'TZ']\n",
    "\n",
    "from typing import List\n",
    "def get_society_label(country: str, peaceful: List[str], nonpeaceful: List[str]) -> str:\n",
    "    if country in peaceful:\n",
    "        return \"peaceful\"\n",
    "    elif country in nonpeaceful:\n",
    "        return \"nonpeaceful\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "    \n",
    "anec_article[\"society\"] = anec_article.country.apply(\n",
    "    get_society_label, peaceful=peaceful_countries, nonpeaceful=non_peaceful_countries)\n",
    "\n",
    "anec_article.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaceful_countries = ['GB', 'AU', 'CA', 'SG', 'NZ', 'IE']\n",
    "non_peaceful_countries = ['PK', 'BD', 'NG', 'KE', 'ZA', 'TZ']\n",
    "\n",
    "from typing import List\n",
    "def get_society_label(country: str, peaceful: List[str], nonpeaceful: List[str]) -> str:\n",
    "    if country in peaceful:\n",
    "        return \"peaceful\"\n",
    "    elif country in nonpeaceful:\n",
    "        return \"nonpeaceful\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "    \n",
    "anec_article[\"society\"] = anec_article.country.apply(\n",
    "    get_society_label, peaceful=peaceful_countries, nonpeaceful=non_peaceful_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['subscribe', 'australia', 'follow', 'listen', 'around'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = anec_article.iloc[0].article_og_text\n",
    "terms = anec_article.iloc[0].top_terms\n",
    "\n",
    "def pretty_og_text(t, terms):\n",
    "    t = re.sub(r\"<\\w>\", \"\", t).strip()\n",
    "    t = re.sub(r\" \\s+\", r\" \", t)\n",
    "    t = re.sub(r'\\s. \"', '.\"', t)\n",
    "    t = re.sub(r' ,', ',', t)\n",
    "    t = re.sub(r\"\\s(.?'\\w)\", r\"\\1\", t)\n",
    "\n",
    "    final_terms = []\n",
    "    for t in word_tokenize(t):\n",
    "        t_ = t.lower()\n",
    "        if t_ in terms or lemmatizer.lemmatize(t_) in terms:\n",
    "            final_terms.append('<span style=\"color: red\">{:s}</span>'.format(t))\n",
    "        else:\n",
    "            final_terms.append(t)\n",
    "\n",
    "    return \" \".join(final_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_cleaned_text(text, top_terms, format_type):\n",
    "    pass\n",
    "\n",
    "def pretty_rnn_text(text, top_terms, format_type):\n",
    "    \n",
    "    if format_type == \"html\":\n",
    "        f_string = '<span style=\"color: red\">{:s}</span>'\n",
    "    elif format_type == \"markdown\":\n",
    "        f_string = '**{:s}**'\n",
    "    else:\n",
    "        f_string = '{:s}'\n",
    "        \n",
    "    for term in top_terms:\n",
    "        text = re.sub(r\"\\b{:s}\\b\".format(term), f_string.format(term), text)\n",
    "        \n",
    "    return text\n",
    "    \n",
    "def make_pretty_text(rnn_text, top_terms, format_type):\n",
    "    pretty = pretty_rnn_text(rnn_text, top_terms, format_type)\n",
    "    return pretty\n",
    "\n",
    "def make_pretty_html(article_id, society, country, title, terms, text, format_type):\n",
    "    if format_type == \"html\":\n",
    "        f_string = '<div>Article #{:d}<br><h3>{:s} - {:s}</h3><strong>{:s}</strong><br><p>Top weighted terms: {:s}</p><p>{:s}</p></div>'\n",
    "    \n",
    "    return f_string.format(article_id, society.title(), country, title, terms, text) \n",
    "    \n",
    "def apply_make_pretty(row, format_type=\"html\"):\n",
    "#     text = make_pretty_text(row.article_text.lower(), row.top_terms, format_type)\n",
    "    text = pretty_og_text(row.article_og_text, row.top_terms)\n",
    "    final_terms = []\n",
    "    for term in sorted(row.top_terms):\n",
    "        if term in lexicon.term.unique():\n",
    "            final_terms.append(\"<strong>{:s}</strong>\".format(term))\n",
    "        else:\n",
    "            final_terms.append(term)\n",
    "            \n",
    "    terms = \", \".join(final_terms)\n",
    "    return make_pretty_html(row.article_id, row.society, row.country, row.article_title, terms, text, format_type)\n",
    "\n",
    "anec_article[\"formatted\"] = anec_article.apply(apply_make_pretty, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = anec_article.groupby(\"society\").apply(lambda x: x.formatted.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Peaceful RAW Article Sample.html\", \"w\") as f:\n",
    "    f.writelines(\"<hr>\".join(formatted[\"peaceful\"]))\n",
    "    f.close()\n",
    "\n",
    "with open(\"Non-Peaceful RAW Article Sample.html\", \"w\") as f:\n",
    "    f.writelines(\"<hr>\".join(formatted[\"nonpeaceful\"]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
